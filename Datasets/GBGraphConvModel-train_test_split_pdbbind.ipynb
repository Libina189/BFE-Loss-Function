{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62fe665-82a2-4f1d-8116-420ca1af6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/libinathomas/miniforge3/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccdd81a-7d48-4583-aaf2-d0fe1f2ed7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61276e2-794b-44b0-9787-67c1551d5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/libinathomas/repos/GBNN/Datasets/pdbbind_300.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae967fb-0294-4018-bedb-77b8c356e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65844a4-af01-4e4d-a750-eebd0e6b1bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>complex-name</th>\n",
       "      <th>gb-complex-etot</th>\n",
       "      <th>gb-complex-1-4-eel</th>\n",
       "      <th>gb-complex-eelec</th>\n",
       "      <th>gb-complex-egb</th>\n",
       "      <th>gb-complex-esurf</th>\n",
       "      <th>gb-protein-etot</th>\n",
       "      <th>gb-protein-1-4-eel</th>\n",
       "      <th>gb-protein-eelect</th>\n",
       "      <th>...</th>\n",
       "      <th>pb-protein-epb</th>\n",
       "      <th>pb-protein-ecavity</th>\n",
       "      <th>pb-ligand-etot</th>\n",
       "      <th>pb-ligand-vdwaals</th>\n",
       "      <th>pb-ligand-eelec</th>\n",
       "      <th>pb-ligand-epb</th>\n",
       "      <th>pb-ligand-ecavity</th>\n",
       "      <th>ddg</th>\n",
       "      <th>enthalpy-gb</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10gs</td>\n",
       "      <td>-16145.9190</td>\n",
       "      <td>18478.8142</td>\n",
       "      <td>-31052.1742</td>\n",
       "      <td>-3659.4630</td>\n",
       "      <td>86.9041</td>\n",
       "      <td>-16042.9095</td>\n",
       "      <td>18034.9833</td>\n",
       "      <td>-30493.1722</td>\n",
       "      <td>...</td>\n",
       "      <td>-3650.6491</td>\n",
       "      <td>87.9920</td>\n",
       "      <td>-565.1881</td>\n",
       "      <td>-10.1928</td>\n",
       "      <td>-416.8647</td>\n",
       "      <td>-141.8681</td>\n",
       "      <td>3.7375</td>\n",
       "      <td>-8.841927</td>\n",
       "      <td>-42.9160</td>\n",
       "      <td>-34.074073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1a1e</td>\n",
       "      <td>-9777.1684</td>\n",
       "      <td>7030.7012</td>\n",
       "      <td>-13515.0036</td>\n",
       "      <td>-3349.3791</td>\n",
       "      <td>56.5130</td>\n",
       "      <td>-9499.3955</td>\n",
       "      <td>7189.5223</td>\n",
       "      <td>-13366.9577</td>\n",
       "      <td>...</td>\n",
       "      <td>-3333.0961</td>\n",
       "      <td>56.2103</td>\n",
       "      <td>-173.5190</td>\n",
       "      <td>-11.4008</td>\n",
       "      <td>-96.6715</td>\n",
       "      <td>-69.9064</td>\n",
       "      <td>4.4598</td>\n",
       "      <td>-8.289306</td>\n",
       "      <td>3.2581</td>\n",
       "      <td>11.547406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 complex-name  gb-complex-etot  gb-complex-1-4-eel  \\\n",
       "0           0         10gs      -16145.9190          18478.8142   \n",
       "1           1         1a1e       -9777.1684           7030.7012   \n",
       "\n",
       "   gb-complex-eelec  gb-complex-egb  gb-complex-esurf  gb-protein-etot  \\\n",
       "0       -31052.1742      -3659.4630           86.9041      -16042.9095   \n",
       "1       -13515.0036      -3349.3791           56.5130       -9499.3955   \n",
       "\n",
       "   gb-protein-1-4-eel  gb-protein-eelect  ...  pb-protein-epb  \\\n",
       "0          18034.9833        -30493.1722  ...      -3650.6491   \n",
       "1           7189.5223        -13366.9577  ...      -3333.0961   \n",
       "\n",
       "   pb-protein-ecavity  pb-ligand-etot  pb-ligand-vdwaals  pb-ligand-eelec  \\\n",
       "0             87.9920       -565.1881           -10.1928        -416.8647   \n",
       "1             56.2103       -173.5190           -11.4008         -96.6715   \n",
       "\n",
       "   pb-ligand-epb  pb-ligand-ecavity       ddg  enthalpy-gb    entropy  \n",
       "0      -141.8681             3.7375 -8.841927     -42.9160 -34.074073  \n",
       "1       -69.9064             4.4598 -8.289306       3.2581  11.547406  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c88b3f-c72f-4e9c-837a-bda3395d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_names_df = df['complex-name'].to_numpy()\n",
    "PDBs = {}\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = '/Users/libinathomas/repos/GBNN/Datasets/pdbbind_complex'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "for f in onlyfiles:\n",
    "    if f.split('.')[0] in complex_names_df:\n",
    "        PDBs.update({f.split('.')[0] : rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + '/' + f)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153de348-bb8f-4432-884f-beae447d1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "TRAIN_SET = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ae5206-54bc-4fc6-a5ca-1b7137a01294",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_ids = []\n",
    "# one_add = 0 if len(PDBs.keys()) % 2 == 0 else 1\n",
    "for k in PDBs.keys():\n",
    "    X_ids.append(k)\n",
    "    X.append(featurizer.featurize(PDBs[k]))\n",
    "split_index = int(len(X) * TRAIN_SET)\n",
    "X = [x[0] for x in X]\n",
    "X_train_featurized = X[:split_index]\n",
    "X_test_featurized = X[split_index:]\n",
    "X_ids_train = X_ids[:split_index]\n",
    "X_ids_test = X_ids[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69721d39-0148-4585-837c-9623d5103427",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_disk = []\n",
    "y_disk = []\n",
    "for i in range(len(X_ids)):\n",
    "    X_disk.append(X[i])\n",
    "    y_disk.append(df[df['complex-name'] == X_ids[i]]['ddg'].to_numpy()[0])\n",
    "w_disk = np.ones([5,12])\n",
    "X_add = []\n",
    "for i in range(len(X_ids)):\n",
    "    X_add.append(df[df['complex-name'] == X_ids[i]][[i for i in df.columns if ((('gb-' in i))\n",
    "                                                          and ('-etot' not in i)) or ('-vdwaals' in i)]].to_numpy()[0])\n",
    "train_dataset = dc.data.DiskDataset.from_numpy(X=X_disk, y=y_disk, w=w_disk, ids=X_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6152df9b-bfb2-446a-9b7f-e1ee7da9a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_add_train, x_add_test, y_train, y_test = [], [], [], []\n",
    "for i in range(len(X_ids_train)):\n",
    "    new_df = df[(df['complex-name'] == X_ids_train[i])]\n",
    "    y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_train.append(new_df[[i for i in df.columns if ((('gb-' in i))\n",
    "                                                          and ('-etot' not in i)) or ('-vdwaals' in i)]].to_numpy()[0])\n",
    "y_train = np.array(y_train)\n",
    "    \n",
    "for i in range(len(X_ids_test)):\n",
    "    new_df = df[(df['complex-name'] == X_ids_train[i])]\n",
    "    y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_test.append(new_df[[i for i in df.columns if ((('gb-' in i))\n",
    "                                                          and ('-etot' not in i)) or ('-vdwaals' in i)]].to_numpy()[0])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34822ce4-9847-4703-bdbc-6fa8979bd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "x_preprocessed_train, x_preprocessed_test = [], []\n",
    "\n",
    "## for X train\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "## for X test\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_test.append(np.array(x_add_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d40218-964f-4d25-89f7-2d050d94354e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## !!!!!!!! important\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m## !!!!!!!! important\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## !!!!!!!! important\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## !!!!!!!! important\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m(batch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "del(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa86cd6-836f-4df0-a995-4095c40c6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_add = np.array(X_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22cb9b3d-8793-4178-9d90-54366e22993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.84788142e+04, -3.10521742e+04, -3.65946300e+03,\n",
       "         8.69041000e+01,  1.80349833e+04, -3.04931722e+04,\n",
       "        -3.67271260e+03,  8.79920000e+01,  4.43830900e+02,\n",
       "        -4.16864700e+02, -1.46368300e+02,  3.73750000e+00,\n",
       "        -4.14363380e+03, -4.07786980e+03, -1.01928000e+01],\n",
       "       [ 7.03070120e+03, -1.35150036e+04, -3.34937910e+03,\n",
       "         5.65130000e+01,  7.18952230e+03, -1.33669577e+04,\n",
       "        -3.37817030e+03,  5.62103000e+01, -1.58821000e+02,\n",
       "        -9.66715000e+01, -6.91305000e+01,  4.45980000e+00,\n",
       "        -1.95158170e+03, -1.90104860e+03, -1.14008000e+01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e158e35b-d888-4310-9535-ab8650930373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "class GBGraphConvModel(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "  def __init__(self, batch_size):\n",
    "    super(GBGraphConvModel, self).__init__()\n",
    "    self.counter = 0\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(64, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(1)\n",
    "    self.dense3 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([.5, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
    "         bias_initializer=initializers.Zeros())\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     inputs = inputs[0]\n",
    "    x = inputs\n",
    "    x_add = X_add\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "#     for i in range(len(self.input_shapes)):\n",
    "#         x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "#     for i in range(1, len(self.input_shapes)):\n",
    "#         x[i] = tf.cast(x[i], tf.int32)\n",
    "#     x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 15])\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    ans = self.dense3(binding_affinity)\n",
    "    ans = tf.reshape(ans, [1, -1])\n",
    "    print(ans)\n",
    "    return ans\n",
    "model = GBGraphConvModel(split_index)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6d68a8-e0d5-44d5-856b-801bc841ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y, y_hat, w):\n",
    "    return tf.keras.losses.mse(y_hat, y)\n",
    "loss_func = lambda y, y_hat, w: tf.keras.losses.mse(y_hat, y)\n",
    "model2 = dc.models.KerasModel(GBGraphConvModel(len(df)), loss = loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eebe3ddd-6d7d-42d1-8111-57f446e5d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "import numpy as np\n",
    "batch_size = len(df)\n",
    "def data_generator(dataset, epochs=30):\n",
    "    for ind, (X_b, y_b, w_b, ids_b) in enumerate(dataset.iterbatches(batch_size, epochs,\n",
    "                                                                   deterministic=False, pad_batches=True)):\n",
    "        multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
    "        inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "        for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "            inputs.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "#        inputs.append(X_add)\n",
    "#         print(inputs[13])\n",
    "        labels = y_b\n",
    "        weights = [w_b]\n",
    "        yield (inputs, labels, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6789fdfc-6186-486f-91d1-1353ef70b985",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 3295, 11, 3295, 991, 1175, 1129, 0, 0, 0, 0, 0, 0, 0, 1\n'y' sizes: 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.input_shapes = [i.shape for i in x_preprocessed_train]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_preprocessed_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 3295, 11, 3295, 991, 1175, 1129, 0, 0, 0, 0, 0, 0, 0, 1\n'y' sizes: 1\n"
     ]
    }
   ],
   "source": [
    "# model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "history = model.fit([x_preprocessed_train], y_train.reshape([1, -1]), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a738e4a-dc65-4a1f-a4fe-92482f299eef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`keras.optimizers.legacy` is not supported in Keras 3. When using `tf.keras`, to continue using a `tf.keras.optimizers.legacy` optimizer, you can install the `tf_keras` package (Keras 2) and set the environment variable `TF_USE_LEGACY_KERAS=True` to configure TensorFlow to use `tf_keras` when accessing `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m his \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/deepchem/models/keras_model.py:412\u001b[0m, in \u001b[0;36mKerasModel.fit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, SequenceCollection):\n\u001b[1;32m    411\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [callbacks]\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_built\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_interval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    414\u001b[0m     manager \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpointManager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint,\n\u001b[1;32m    415\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir,\n\u001b[1;32m    416\u001b[0m                                          max_checkpoints_to_keep)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/deepchem/models/keras_model.py:270\u001b[0m, in \u001b[0;36mKerasModel._ensure_built\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_global_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\u001b[38;5;241m0\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tf_optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_tf_optimizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_global_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tf_optimizer,\n\u001b[1;32m    273\u001b[0m                                        model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/deepchem/models/optimizers.py:222\u001b[0m, in \u001b[0;36mAdam._create_tf_optimizer\u001b[0;34m(self, global_step)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbeta_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbeta_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/optimizers/__init__.py:115\u001b[0m, in \u001b[0;36mLegacyOptimizerWarning.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.optimizers.legacy` is not supported in Keras 3. When using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.keras`, to continue using a `tf.keras.optimizers.legacy` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer, you can install the `tf_keras` package (Keras 2) and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset the environment variable `TF_USE_LEGACY_KERAS=True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigure TensorFlow to use `tf_keras` when accessing `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: `keras.optimizers.legacy` is not supported in Keras 3. When using `tf.keras`, to continue using a `tf.keras.optimizers.legacy` optimizer, you can install the `tf_keras` package (Keras 2) and set the environment variable `TF_USE_LEGACY_KERAS=True` to configure TensorFlow to use `tf_keras` when accessing `tf.keras`."
     ]
    }
   ],
   "source": [
    "his = model2.fit_generator(data_generator(train_dataset, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a9c8ba9-8a50-4373-a0d8-931520d156bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "model.modify_graphgather(len(X) - split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15e72a1e-7071-44ad-bf2d-d592f03edc0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mx_test\u001b[49m, y_test\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test.reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "570fb38e-dbea-417e-ab8e-0f5de7f68d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.220932405998316"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(38.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a79a448-1422-4dbf-a7a2-d514aa95a889",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "550375cf-d86d-48f2-9fbb-8c3ecf032e58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 3295, 11, 3295, 991, 1175, 1129, 0, 0, 0, 0, 0, 0, 0, 1\n'y' sizes: 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_preprocessed_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 3295, 11, 3295, 991, 1175, 1129, 0, 0, 0, 0, 0, 0, 0, 1\n'y' sizes: 1\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_preprocessed_train], y_train.reshape([1, -1]), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6012a2-4a18-4320-abca-b25fc0851b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'complex-name', 'gb-complex-etot', 'gb-complex-1-4-eel',\n",
       "       'gb-complex-eelec', 'gb-complex-egb', 'gb-complex-esurf',\n",
       "       'gb-protein-etot', 'gb-protein-1-4-eel', 'gb-protein-eelect',\n",
       "       'gb-protein-egb', 'gb-protein-esurf', 'gb-ligand-etot',\n",
       "       'gb-ligand-1-4-eel', 'gb-ligand-eelec', 'gb-ligand-egb',\n",
       "       'gb-ligand-esurf', 'pb-complex-etot', 'pb-complex-vdwaals',\n",
       "       'pb-complex-eelect', 'pb-complex-epb', 'pb-complex-ecavity',\n",
       "       'pb-protein-etot', 'pb-protein-vdwaals', 'pb-protein-eelec',\n",
       "       'pb-protein-epb', 'pb-protein-ecavity', 'pb-ligand-etot',\n",
       "       'pb-ligand-vdwaals', 'pb-ligand-eelec', 'pb-ligand-epb',\n",
       "       'pb-ligand-ecavity', 'ddg', 'enthalpy-gb', 'entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af40d64a-4312-4ea3-9b71-1a25208c3343",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'EX _H_(kcal/mol)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'EX _H_(kcal/mol)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean((\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEX _H_(kcal/mol)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy() \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgb_delta_H\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'EX _H_(kcal/mol)'"
     ]
    }
   ],
   "source": [
    "np.sqrt(np.mean((df['EX _H_(kcal/mol)'].to_numpy() - df['gb_delta_H'].to_numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f0940-1ce7-4949-b662-2711e6fa90fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
